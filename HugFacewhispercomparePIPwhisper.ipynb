{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model1 = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(\"cuda\")\n",
    "model2=whisper.load_model(\"small\")\n",
    "\n",
    "print(model1)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperForConditionalGeneration(\n",
      "  (model): WhisperModel(\n",
      "    (encoder): WhisperEncoder(\n",
      "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (embed_positions): Embedding(1500, 768)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x WhisperEncoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): WhisperDecoder(\n",
      "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
      "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x WhisperDecoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper(\n",
      "  (encoder): AudioEncoder(\n",
      "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (attn): MultiHeadAttention(\n",
      "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TextDecoder(\n",
      "    (token_embedding): Embedding(51865, 768)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (attn): MultiHeadAttention(\n",
      "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (cross_attn): MultiHeadAttention(\n",
      "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
      "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001C380ABFBC0>\n"
     ]
    }
   ],
   "source": [
    "print(model1.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001C380ABF920>\n"
     ]
    }
   ],
   "source": [
    "print(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-6.4545e-03, -6.4545e-03, -1.4877e-02],\n",
      "         [ 2.8275e-02,  2.9892e-02,  1.0704e-02],\n",
      "         [ 1.9293e-03, -3.9795e-02, -6.6528e-02],\n",
      "         ...,\n",
      "         [-3.1033e-03, -9.7122e-03, -3.2463e-03],\n",
      "         [-1.6451e-03, -1.1742e-02, -2.6531e-03],\n",
      "         [-1.2085e-02, -3.1403e-02, -1.8692e-02]],\n",
      "\n",
      "        [[-7.7286e-03, -7.0801e-03, -1.3550e-02],\n",
      "         [ 1.1520e-02,  1.1215e-02,  1.0849e-02],\n",
      "         [-1.5182e-02, -1.9730e-02, -1.2169e-02],\n",
      "         ...,\n",
      "         [ 8.5068e-04, -4.4708e-03, -3.3913e-03],\n",
      "         [ 1.1425e-03, -4.7722e-03, -2.8610e-03],\n",
      "         [-8.8978e-04, -9.6664e-03, -7.0610e-03]],\n",
      "\n",
      "        [[-4.4632e-03, -5.4741e-03,  2.8992e-03],\n",
      "         [-8.3771e-03, -9.0103e-03, -3.7041e-03],\n",
      "         [ 1.8738e-02,  3.0914e-02,  3.7140e-02],\n",
      "         ...,\n",
      "         [-2.5131e-02,  3.0762e-02, -3.3447e-02],\n",
      "         [-2.6749e-02,  2.4811e-02, -3.2776e-02],\n",
      "         [-4.0497e-02,  3.1616e-02, -5.5725e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4620e-03, -5.8975e-03, -8.1863e-03],\n",
      "         [ 2.4090e-03, -4.5738e-03, -4.8981e-03],\n",
      "         [ 8.4610e-03,  2.0798e-02,  1.6586e-02],\n",
      "         ...,\n",
      "         [-3.9093e-02,  1.2154e-02, -4.1656e-02],\n",
      "         [-3.5950e-02,  1.8616e-02, -3.2471e-02],\n",
      "         [-2.3071e-02,  6.7444e-02, -3.5400e-03]],\n",
      "\n",
      "        [[-1.1978e-02, -1.2314e-02, -1.0803e-02],\n",
      "         [ 3.2501e-03,  9.5749e-03,  3.8700e-03],\n",
      "         [-2.3766e-03, -7.5989e-03, -9.2087e-03],\n",
      "         ...,\n",
      "         [ 1.0729e-03,  2.1515e-03,  1.9178e-03],\n",
      "         [ 1.2999e-03,  6.2799e-04,  2.5806e-03],\n",
      "         [-2.7905e-03,  4.3511e-05,  1.4696e-03]],\n",
      "\n",
      "        [[-7.9193e-03, -1.0780e-02, -1.5732e-02],\n",
      "         [-3.7441e-03, -1.5497e-03, -2.4090e-03],\n",
      "         [-6.4015e-05,  2.3422e-03,  1.0805e-03],\n",
      "         ...,\n",
      "         [-1.6510e-02, -1.5717e-02, -1.9821e-02],\n",
      "         [-7.9269e-03, -8.7585e-03, -1.4259e-02],\n",
      "         [-2.6642e-02, -2.9190e-02, -3.2776e-02]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model2.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "478\n"
     ]
    }
   ],
   "source": [
    "p1=model1.parameters()\n",
    "p2=model2.parameters()\n",
    "\n",
    "p1=list(p1)\n",
    "p2=list(p2)\n",
    "\n",
    "print(len(p1))\n",
    "print(len(p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([448, 768]) torch.Size([51865, 768])\n",
      "torch.Size([51865, 768]) torch.Size([448, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 3072]) torch.Size([768, 3072])\n",
      "torch.Size([3072]) torch.Size([3072])\n",
      "torch.Size([3072, 768]) torch.Size([3072, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([768]) torch.Size([768, 768])\n",
      "torch.Size([768, 768]) torch.Size([768])\n",
      "torch.Size([768, 768]) torch.Size([768, 768])\n",
      "torch.Size([1500, 768]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768, 768, 3])\n",
      "torch.Size([768, 768, 3]) torch.Size([768])\n",
      "torch.Size([768]) torch.Size([768, 80, 3])\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(p1[::-1],p2[::-1]):\n",
    "    print(i.shape,j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n",
      "-5\n",
      "-6\n",
      "-7\n",
      "-8\n",
      "-9\n",
      "-10\n",
      "-11\n",
      "-12\n",
      "-13\n",
      "tensor([-5.2177e-02, -6.9855e-01,  1.7758e-01, -1.3082e-01,  3.6549e-01,\n",
      "         4.7774e-01,  7.0648e-02,  1.0849e-01,  1.5796e-01,  1.8457e-01,\n",
      "        -7.0587e-02,  7.9803e-02, -2.6761e-01,  2.5931e-01,  1.9217e-01,\n",
      "         1.8898e-01,  1.7426e-01, -3.3911e-01,  1.2841e+00,  5.4953e-01,\n",
      "         3.0524e-01,  2.0978e-01,  8.5953e-02, -1.0439e-01, -1.4999e-02,\n",
      "        -7.4619e-01, -1.9568e-01, -2.3608e-01, -1.1520e-01, -3.2347e-01,\n",
      "        -1.4545e-01,  3.9697e-01,  4.3474e-01, -4.3004e-01,  5.0190e-01,\n",
      "         5.7964e-02,  2.5565e-01, -3.2632e-01, -1.4642e+00, -3.9830e-01,\n",
      "         1.8735e-01,  8.9439e-02,  4.3879e-02,  1.4465e-02,  8.7531e-01,\n",
      "         2.3041e-03, -1.4583e-01, -8.8674e-01, -1.3414e-01, -3.9186e-01,\n",
      "        -6.3588e-01,  2.5578e-01,  3.2036e-01, -1.0587e-01, -2.4416e-01,\n",
      "        -2.4109e-01, -2.2479e-01, -1.2955e-01, -1.5819e-01,  4.5978e-01,\n",
      "        -5.0156e-02,  2.0737e-01, -7.2632e-03,  4.3707e-03, -4.2580e-01,\n",
      "         4.8157e-02, -1.5050e+00, -5.3029e-01,  3.5504e-01, -3.6676e-01,\n",
      "        -8.0475e-02, -4.4823e-01,  2.8490e-01,  5.4999e-01, -2.0340e-02,\n",
      "         1.0152e-01, -3.2794e-01, -2.6816e-01,  7.3897e-01,  1.6250e-01,\n",
      "        -8.4473e-02,  1.1563e-01,  3.0649e-01, -4.0796e-01,  1.6269e-01,\n",
      "         3.8120e-01, -2.7060e-01,  5.6274e-02,  5.7157e-01, -6.4777e-01,\n",
      "        -3.8425e-01,  1.1215e+00,  2.9297e-01, -1.9435e-01, -3.7106e-01,\n",
      "        -1.5649e-01, -4.0820e-01, -1.5277e-01, -4.2661e-01, -1.9320e+00,\n",
      "        -1.4249e-01, -1.7343e-01,  5.6433e-01,  3.5338e-01, -7.0496e-02,\n",
      "         1.1157e-01,  3.0495e-01, -7.1637e-01, -1.0304e-01, -9.8511e-02,\n",
      "        -2.0639e-01,  1.9409e-02, -5.2256e-01, -2.8894e-01, -3.0060e-01,\n",
      "        -2.0736e+00,  1.7059e-02, -1.6296e-01, -1.2488e+00,  4.2593e-01,\n",
      "         9.0942e-02,  6.3446e-01,  6.6528e-01,  2.8414e-01, -7.5470e-02,\n",
      "        -1.8404e-01, -4.8987e-01,  1.6074e-01,  7.8023e-01, -8.3817e-01,\n",
      "         6.1061e-01,  5.5599e-02, -4.9121e-01, -1.1000e-01, -6.3220e-01,\n",
      "         2.8421e-01,  7.5352e-01, -2.2363e-01,  5.8279e-01, -2.4301e-01,\n",
      "        -4.9158e-01,  2.2028e-01, -1.1324e+00, -6.9086e-01, -1.1157e-01,\n",
      "         2.9713e-01, -7.3560e-01, -2.6043e-01, -2.2412e-01,  5.3993e-01,\n",
      "        -1.5689e-01,  1.2024e+00,  5.5088e-02, -7.7303e-01, -4.2453e-01,\n",
      "        -3.1158e-02,  2.3023e-01, -3.3027e-01, -3.2825e-01,  4.0871e-01,\n",
      "        -4.4441e-02, -1.9652e-01,  3.9819e-01, -5.6329e-01, -2.3857e-01,\n",
      "        -3.4354e-01,  7.5399e-01,  1.3524e-01,  3.1250e-02,  6.5277e-01,\n",
      "         7.6373e-01, -4.4800e-02, -7.5542e-01,  7.4893e-01,  3.2251e-01,\n",
      "        -1.9275e-01, -3.2178e-01, -1.3395e+00,  3.7218e-01, -7.7804e-01,\n",
      "         3.2601e-01, -2.0444e-01,  1.8069e+00,  9.8267e-02, -1.1017e-01,\n",
      "         7.9702e-01,  9.7878e-02, -8.3054e-02, -6.4511e-01, -5.0531e-01,\n",
      "         7.1597e-01, -1.8195e-01,  2.1010e+00, -6.8414e-01, -3.9975e-01,\n",
      "        -5.4840e-02, -6.5384e-01,  2.7350e-01, -3.3466e-01, -1.1785e+00,\n",
      "         1.3232e-01,  6.4970e-01,  1.5454e-01, -1.7883e-01, -9.8203e-01,\n",
      "        -4.1651e-01,  3.0518e-04,  2.3413e-01,  2.2690e-01,  3.1848e-01,\n",
      "        -1.4845e+00, -1.0668e-01,  3.7874e-01, -1.4879e+00,  2.2423e-02,\n",
      "        -1.0505e+00, -4.0185e-01,  7.3993e-01,  1.0642e-01, -2.4191e-01,\n",
      "         2.0349e-01, -4.1443e-01, -1.3702e-01, -2.8137e-02, -8.2950e-01,\n",
      "        -3.2498e-01, -1.7441e-01,  1.4099e+00,  2.1854e-01, -1.0800e+00,\n",
      "        -1.5254e+00, -4.0298e-01,  2.7362e-01,  1.9754e-01, -3.6780e-01,\n",
      "         5.7220e-01,  4.8553e-01, -5.2911e-01, -6.0778e-01,  2.7859e-01,\n",
      "         5.3778e-01, -4.9686e-01,  2.5525e-01,  9.5473e-01,  2.1299e-01,\n",
      "         1.6919e-01,  9.8480e-01,  7.3996e-01,  1.8567e-01, -4.0353e-01,\n",
      "         1.1304e-01,  8.7463e-02,  7.7625e-01, -4.4148e-01, -2.3770e-01,\n",
      "        -1.6953e-01,  1.5332e-01,  9.6802e-02,  5.4851e-01, -1.0931e+00,\n",
      "         5.2895e-01, -2.4855e-01, -1.7361e-01, -1.4791e-01, -1.9438e-01,\n",
      "         1.9010e+00, -7.8935e-01,  3.0011e-01, -5.7434e-02,  2.0825e-01,\n",
      "         5.1620e-02,  6.1538e-01, -2.1450e+00,  2.5162e-01, -7.6767e-01,\n",
      "         1.2363e-01, -3.3569e-02,  4.1650e-01,  1.0508e+00,  7.6105e-01,\n",
      "         2.8857e-01,  9.5352e-01,  7.5201e-01, -1.8707e-01,  7.3135e-01,\n",
      "        -5.9576e-01,  4.4365e-01,  3.4973e-01,  3.2347e-01,  4.5190e-01,\n",
      "         1.8311e-03,  4.8877e-01,  2.7051e-01, -1.3676e-01, -2.9941e-01,\n",
      "         5.3329e-02, -9.1721e-02,  2.2229e-01,  3.4738e-01,  5.9235e-02,\n",
      "        -5.6030e-02, -1.2256e-01, -8.9363e-02, -1.0844e+00, -5.4974e-01,\n",
      "         2.1948e-01, -1.2686e-01, -4.7552e-01,  8.3182e-01,  4.1122e-03,\n",
      "         5.0345e-01, -2.6539e-02,  2.8842e-01, -2.5877e-01, -7.7576e-02,\n",
      "        -5.4626e-03,  2.3331e-02,  1.3733e-01,  8.4497e-01,  5.3279e-01,\n",
      "         6.7030e-01, -2.3975e-01,  1.3783e-01,  1.5308e+00, -1.0841e-01,\n",
      "        -6.6492e-01,  8.0444e-02,  1.0806e-01, -1.1367e+00,  2.0943e-01,\n",
      "        -1.0756e-01,  2.4271e-01, -5.5664e-02, -1.8861e-01,  3.0206e-01,\n",
      "        -6.3802e-01,  9.0942e-03, -4.3311e-01,  7.2815e-02, -8.0511e-02,\n",
      "         6.7749e-02, -6.3599e-02, -5.0456e-01, -2.1393e-01,  2.7856e-01,\n",
      "         1.9017e-01, -2.3529e-02, -2.1362e-03, -2.9486e-01, -2.0279e-02,\n",
      "        -2.7733e-01,  5.6409e-01, -1.9348e-01,  4.7528e-01,  2.8595e-02,\n",
      "         2.5146e-01,  1.6583e-01, -3.8257e-01, -2.2729e-01, -2.2437e-01,\n",
      "        -2.0129e-01, -2.7604e-01, -1.8314e-01,  7.7124e-01, -4.0448e-01,\n",
      "        -2.5671e-01, -3.8330e-02,  3.3862e-01,  2.4385e-01,  1.2096e-01,\n",
      "         4.0338e-01, -6.5971e-02,  7.9836e-01,  3.8342e-01,  2.2669e-01,\n",
      "        -3.8748e-01, -1.8903e-01,  2.4120e-01, -3.9466e-01,  2.9356e-01,\n",
      "         3.2886e-01,  3.4929e+00, -6.0776e-02,  9.6857e-01, -3.1201e-01,\n",
      "        -1.8881e+00, -2.8625e-02, -3.2589e-01, -1.0733e+00, -4.9420e-01,\n",
      "         7.5186e-01, -1.1285e-01,  2.7104e-01,  4.2313e-01, -4.1257e-01,\n",
      "        -6.8283e-01, -3.5889e-02,  8.8351e-01, -1.1765e-01,  4.7260e-01,\n",
      "         6.3568e-01, -2.7069e-02, -4.4390e-01,  2.0941e-01, -2.9505e-01,\n",
      "        -2.0058e-01,  4.7462e-01, -6.0558e-01, -1.5799e+00, -4.0707e-01,\n",
      "         3.4325e-02, -3.2857e-01,  3.4905e-01,  7.5580e-01,  7.4730e-01,\n",
      "         5.0923e-01, -2.3022e-01,  2.8759e-01, -5.9238e-01,  6.6284e-02,\n",
      "         1.6083e-01, -5.8116e-01, -1.6231e-01, -5.3090e-01, -4.3079e-01,\n",
      "         5.7922e-02,  7.6923e-01,  2.9211e-01, -3.6963e-01,  4.7504e-01,\n",
      "        -6.7160e-01, -2.2261e+00,  5.3818e-01, -6.5417e-01, -2.0819e-01,\n",
      "        -1.6605e-01,  3.5492e-01,  1.0974e-01, -1.7119e-01, -5.7812e-01,\n",
      "        -1.5472e-01,  7.3349e-02,  3.6551e-01,  5.1483e-02, -2.9779e-01,\n",
      "         6.4148e-02,  2.7458e-01, -4.9719e-01,  6.4169e-01, -2.8770e-02,\n",
      "        -7.9956e-01,  2.2318e-01, -5.7814e-01,  7.7135e-01, -2.5745e-01,\n",
      "        -2.4768e-01, -1.6235e-02,  1.3721e-01, -1.2203e+00,  1.4600e-01,\n",
      "         1.5942e-01, -1.1823e-01,  2.3804e-02, -5.6482e-01, -6.7499e-01,\n",
      "         1.3516e-01, -4.7977e-01,  2.6260e-01, -3.5938e-01, -2.5635e-03,\n",
      "        -4.3652e-01,  3.1323e-01, -9.2505e-01, -2.5092e-01, -2.9358e-01,\n",
      "         1.6501e-01, -2.3550e-01,  2.3267e-01, -1.3337e-01,  5.5023e-01,\n",
      "        -5.4855e-02,  2.5369e-01, -9.8498e-01,  2.4066e-01, -2.1075e-01,\n",
      "         4.3091e-02,  1.3448e-01, -1.9727e-01,  4.2993e-01,  1.6357e-01,\n",
      "        -6.7151e-01,  5.4312e-01,  1.0796e-01, -4.2923e-02, -6.3257e-01,\n",
      "         1.0189e+00, -7.6355e-02,  2.6146e+00, -3.2749e-02, -3.4814e-01,\n",
      "         3.0261e-01,  8.9447e-02, -5.8911e-01, -2.8587e-01,  4.8059e-01,\n",
      "         1.7285e-01,  5.1453e-02,  2.4101e-01,  9.0546e-02, -5.1880e-04,\n",
      "         2.4304e-01,  5.5164e-01, -7.4027e-01, -7.3509e-01,  1.3641e-02,\n",
      "         6.1279e-02, -7.1526e-03,  1.6314e-01, -1.8271e-01, -3.4702e-01,\n",
      "        -5.1184e-01, -6.6192e-01, -1.4417e-01, -3.8217e-01,  7.3846e-01,\n",
      "        -3.5737e-01,  4.1521e-01, -1.3359e-02, -3.7317e-01, -4.2844e-01,\n",
      "        -4.2000e-01,  2.6630e-01, -5.2032e-02,  1.8779e+00, -6.7764e-02,\n",
      "        -6.9545e-01,  4.8828e-01,  1.6162e-01, -3.7860e-01,  3.8171e-01,\n",
      "        -3.4927e-01,  4.5800e-01,  4.6469e-01, -4.5459e-01, -3.7720e-01,\n",
      "        -1.3334e-01,  2.1767e-01,  1.9542e-01,  5.4779e-03, -2.4581e-01,\n",
      "        -6.6785e-01, -4.3037e-02, -5.3918e-01,  6.1852e-01,  1.5411e-01,\n",
      "         3.1190e-01,  1.0744e-01, -9.9014e-02,  8.6374e-01, -4.1872e-02,\n",
      "         5.1667e-01, -1.0440e-01,  3.8463e-01, -1.9473e-01,  2.5108e-01,\n",
      "        -5.9593e-02,  1.8890e-01,  7.2763e-01,  1.6380e+00, -2.8275e-01,\n",
      "        -9.1621e-02,  2.0142e-01,  1.8817e-01, -3.8675e-01,  1.4947e-01,\n",
      "        -5.5193e-01,  2.7429e-01, -2.7203e-01, -2.3532e-01,  3.3990e-01,\n",
      "        -1.7493e-01, -4.9512e-01, -3.0600e-01,  5.3857e-01,  7.2879e-01,\n",
      "        -1.6930e-01, -2.8552e-01, -2.5522e-01, -9.9426e-02, -6.1127e-01,\n",
      "         7.0313e-01, -5.3931e-01,  2.4017e-02, -6.3193e-01, -1.2030e-01,\n",
      "        -1.5668e-01,  3.4717e-01,  3.2861e-01, -3.7201e-01,  7.7856e-01,\n",
      "        -5.9563e-02, -4.6271e-01, -3.8550e-01, -1.1187e+00, -4.9274e-01,\n",
      "         1.4276e-01, -3.5663e-01,  3.1699e-01, -2.4521e-01,  4.1776e-01,\n",
      "         3.0847e-01,  2.9633e-02,  2.4680e-01, -9.8145e-02,  1.0238e+00,\n",
      "        -2.0129e-01, -4.4741e-01,  5.1208e-01, -1.0916e+00,  2.3746e-01,\n",
      "         3.5986e-01, -1.5395e-01, -2.8348e-01,  5.5225e-01,  3.3545e-01,\n",
      "         1.9420e-01,  5.4416e-01, -6.6931e-01, -2.8052e+00,  8.0005e-01,\n",
      "         8.1177e-03,  7.5745e-01,  4.1010e-01, -5.3699e-01,  3.8895e-01,\n",
      "         2.8561e-01, -1.7245e-01, -5.7678e-01,  7.5873e-01,  1.4862e-01,\n",
      "        -3.1542e-01, -9.5577e-02, -5.2757e-02, -7.1869e-02,  5.6244e-02,\n",
      "        -2.8314e-01,  4.6809e-01, -4.8660e-02, -1.5292e+00, -3.8391e-01,\n",
      "         5.2594e-01, -4.5035e-01, -6.4391e-01,  1.6340e+00,  6.0416e-01,\n",
      "        -2.3431e-01, -7.3074e-02, -9.8450e-02, -2.0974e-01, -1.0996e-01,\n",
      "        -1.0809e+00, -2.3918e-01,  2.8224e-01,  3.2124e-01,  5.1051e-01,\n",
      "         2.8500e-02,  3.2928e-01, -1.1821e-01,  2.4417e-01,  5.0534e-01,\n",
      "         3.2452e-01, -7.0694e-01,  4.5901e-01, -8.7418e-02, -2.1820e-02,\n",
      "         6.6589e-02,  2.3043e-02,  2.0550e+00,  1.1678e-01,  7.4187e-01,\n",
      "        -7.8706e-01,  3.2487e-01,  5.5169e-01, -7.0221e-02, -3.6552e-02,\n",
      "         2.0496e-01,  1.6504e-01,  2.9150e-01, -2.2522e-01, -5.3033e-01,\n",
      "        -1.3788e-01,  9.6802e-02, -3.9612e-02, -5.1521e-01, -1.3815e-01,\n",
      "        -9.3456e-02, -7.8745e-01,  1.6968e-02,  2.3137e-01, -6.1188e-01,\n",
      "        -1.9049e-01,  9.6893e-02,  3.1367e-01,  4.2511e-02, -8.9851e-02,\n",
      "         2.4814e-01,  3.5767e-01, -1.6501e-01,  7.0547e-01,  7.6396e-01,\n",
      "         2.9560e-01,  3.8254e-01,  1.7145e-01, -3.0119e-01,  5.0491e-02,\n",
      "        -1.1118e-01,  2.5299e-02, -1.3921e-01, -3.1543e-01, -3.0762e-02,\n",
      "        -2.7916e-02,  7.2289e-02, -1.8023e-01, -1.0268e-01,  1.8915e-01,\n",
      "        -5.1685e-01, -4.7980e-01, -8.6037e-02,  1.4575e-01,  2.9779e-01,\n",
      "         9.0887e-01, -2.8299e-01,  1.1142e+00,  1.2082e-01,  3.5497e-01,\n",
      "         3.1739e-01, -1.1378e-01, -2.4493e-01,  4.4655e-02,  5.8755e-01,\n",
      "         3.1973e-01, -2.0746e-01,  1.7741e-01,  4.2509e-01, -1.8172e-01,\n",
      "         1.1059e+00, -2.1492e+00,  1.4259e-01,  2.4577e-01,  1.7609e-02,\n",
      "         1.0863e-01, -1.4221e+00,  1.8454e-01,  3.6090e-01,  6.6748e-01,\n",
      "         2.9144e-02,  1.6987e-02, -4.3219e-01,  3.2104e-01, -2.3010e-01,\n",
      "        -4.3396e-01,  1.5919e+00,  1.6080e-01, -2.8912e-01, -1.1353e-01,\n",
      "         1.3937e-01,  2.6058e-01, -1.3199e-01], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1,-len(p1),-1):\n",
    "    print(i)\n",
    "    if((p1[i]-p2[i]).sum()!=0):\n",
    "        print(p1[i]-p2[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.2177e-02, -6.9855e-01,  1.7758e-01, -1.3082e-01,  3.6549e-01,\n",
      "         4.7774e-01,  7.0648e-02,  1.0849e-01,  1.5796e-01,  1.8457e-01,\n",
      "        -7.0587e-02,  7.9803e-02, -2.6761e-01,  2.5931e-01,  1.9217e-01,\n",
      "         1.8898e-01,  1.7426e-01, -3.3911e-01,  1.2841e+00,  5.4953e-01,\n",
      "         3.0524e-01,  2.0978e-01,  8.5953e-02, -1.0439e-01, -1.4999e-02,\n",
      "        -7.4619e-01, -1.9568e-01, -2.3608e-01, -1.1520e-01, -3.2347e-01,\n",
      "        -1.4545e-01,  3.9697e-01,  4.3474e-01, -4.3004e-01,  5.0190e-01,\n",
      "         5.7964e-02,  2.5565e-01, -3.2632e-01, -1.4642e+00, -3.9830e-01,\n",
      "         1.8735e-01,  8.9439e-02,  4.3879e-02,  1.4465e-02,  8.7531e-01,\n",
      "         2.3041e-03, -1.4583e-01, -8.8674e-01, -1.3414e-01, -3.9186e-01,\n",
      "        -6.3588e-01,  2.5578e-01,  3.2036e-01, -1.0587e-01, -2.4416e-01,\n",
      "        -2.4109e-01, -2.2479e-01, -1.2955e-01, -1.5819e-01,  4.5978e-01,\n",
      "        -5.0156e-02,  2.0737e-01, -7.2632e-03,  4.3707e-03, -4.2580e-01,\n",
      "         4.8157e-02, -1.5050e+00, -5.3029e-01,  3.5504e-01, -3.6676e-01,\n",
      "        -8.0475e-02, -4.4823e-01,  2.8490e-01,  5.4999e-01, -2.0340e-02,\n",
      "         1.0152e-01, -3.2794e-01, -2.6816e-01,  7.3897e-01,  1.6250e-01,\n",
      "        -8.4473e-02,  1.1563e-01,  3.0649e-01, -4.0796e-01,  1.6269e-01,\n",
      "         3.8120e-01, -2.7060e-01,  5.6274e-02,  5.7157e-01, -6.4777e-01,\n",
      "        -3.8425e-01,  1.1215e+00,  2.9297e-01, -1.9435e-01, -3.7106e-01,\n",
      "        -1.5649e-01, -4.0820e-01, -1.5277e-01, -4.2661e-01, -1.9320e+00,\n",
      "        -1.4249e-01, -1.7343e-01,  5.6433e-01,  3.5338e-01, -7.0496e-02,\n",
      "         1.1157e-01,  3.0495e-01, -7.1637e-01, -1.0304e-01, -9.8511e-02,\n",
      "        -2.0639e-01,  1.9409e-02, -5.2256e-01, -2.8894e-01, -3.0060e-01,\n",
      "        -2.0736e+00,  1.7059e-02, -1.6296e-01, -1.2488e+00,  4.2593e-01,\n",
      "         9.0942e-02,  6.3446e-01,  6.6528e-01,  2.8414e-01, -7.5470e-02,\n",
      "        -1.8404e-01, -4.8987e-01,  1.6074e-01,  7.8023e-01, -8.3817e-01,\n",
      "         6.1061e-01,  5.5599e-02, -4.9121e-01, -1.1000e-01, -6.3220e-01,\n",
      "         2.8421e-01,  7.5352e-01, -2.2363e-01,  5.8279e-01, -2.4301e-01,\n",
      "        -4.9158e-01,  2.2028e-01, -1.1324e+00, -6.9086e-01, -1.1157e-01,\n",
      "         2.9713e-01, -7.3560e-01, -2.6043e-01, -2.2412e-01,  5.3993e-01,\n",
      "        -1.5689e-01,  1.2024e+00,  5.5088e-02, -7.7303e-01, -4.2453e-01,\n",
      "        -3.1158e-02,  2.3023e-01, -3.3027e-01, -3.2825e-01,  4.0871e-01,\n",
      "        -4.4441e-02, -1.9652e-01,  3.9819e-01, -5.6329e-01, -2.3857e-01,\n",
      "        -3.4354e-01,  7.5399e-01,  1.3524e-01,  3.1250e-02,  6.5277e-01,\n",
      "         7.6373e-01, -4.4800e-02, -7.5542e-01,  7.4893e-01,  3.2251e-01,\n",
      "        -1.9275e-01, -3.2178e-01, -1.3395e+00,  3.7218e-01, -7.7804e-01,\n",
      "         3.2601e-01, -2.0444e-01,  1.8069e+00,  9.8267e-02, -1.1017e-01,\n",
      "         7.9702e-01,  9.7878e-02, -8.3054e-02, -6.4511e-01, -5.0531e-01,\n",
      "         7.1597e-01, -1.8195e-01,  2.1010e+00, -6.8414e-01, -3.9975e-01,\n",
      "        -5.4840e-02, -6.5384e-01,  2.7350e-01, -3.3466e-01, -1.1785e+00,\n",
      "         1.3232e-01,  6.4970e-01,  1.5454e-01, -1.7883e-01, -9.8203e-01,\n",
      "        -4.1651e-01,  3.0518e-04,  2.3413e-01,  2.2690e-01,  3.1848e-01,\n",
      "        -1.4845e+00, -1.0668e-01,  3.7874e-01, -1.4879e+00,  2.2423e-02,\n",
      "        -1.0505e+00, -4.0185e-01,  7.3993e-01,  1.0642e-01, -2.4191e-01,\n",
      "         2.0349e-01, -4.1443e-01, -1.3702e-01, -2.8137e-02, -8.2950e-01,\n",
      "        -3.2498e-01, -1.7441e-01,  1.4099e+00,  2.1854e-01, -1.0800e+00,\n",
      "        -1.5254e+00, -4.0298e-01,  2.7362e-01,  1.9754e-01, -3.6780e-01,\n",
      "         5.7220e-01,  4.8553e-01, -5.2911e-01, -6.0778e-01,  2.7859e-01,\n",
      "         5.3778e-01, -4.9686e-01,  2.5525e-01,  9.5473e-01,  2.1299e-01,\n",
      "         1.6919e-01,  9.8480e-01,  7.3996e-01,  1.8567e-01, -4.0353e-01,\n",
      "         1.1304e-01,  8.7463e-02,  7.7625e-01, -4.4148e-01, -2.3770e-01,\n",
      "        -1.6953e-01,  1.5332e-01,  9.6802e-02,  5.4851e-01, -1.0931e+00,\n",
      "         5.2895e-01, -2.4855e-01, -1.7361e-01, -1.4791e-01, -1.9438e-01,\n",
      "         1.9010e+00, -7.8935e-01,  3.0011e-01, -5.7434e-02,  2.0825e-01,\n",
      "         5.1620e-02,  6.1538e-01, -2.1450e+00,  2.5162e-01, -7.6767e-01,\n",
      "         1.2363e-01, -3.3569e-02,  4.1650e-01,  1.0508e+00,  7.6105e-01,\n",
      "         2.8857e-01,  9.5352e-01,  7.5201e-01, -1.8707e-01,  7.3135e-01,\n",
      "        -5.9576e-01,  4.4365e-01,  3.4973e-01,  3.2347e-01,  4.5190e-01,\n",
      "         1.8311e-03,  4.8877e-01,  2.7051e-01, -1.3676e-01, -2.9941e-01,\n",
      "         5.3329e-02, -9.1721e-02,  2.2229e-01,  3.4738e-01,  5.9235e-02,\n",
      "        -5.6030e-02, -1.2256e-01, -8.9363e-02, -1.0844e+00, -5.4974e-01,\n",
      "         2.1948e-01, -1.2686e-01, -4.7552e-01,  8.3182e-01,  4.1122e-03,\n",
      "         5.0345e-01, -2.6539e-02,  2.8842e-01, -2.5877e-01, -7.7576e-02,\n",
      "        -5.4626e-03,  2.3331e-02,  1.3733e-01,  8.4497e-01,  5.3279e-01,\n",
      "         6.7030e-01, -2.3975e-01,  1.3783e-01,  1.5308e+00, -1.0841e-01,\n",
      "        -6.6492e-01,  8.0444e-02,  1.0806e-01, -1.1367e+00,  2.0943e-01,\n",
      "        -1.0756e-01,  2.4271e-01, -5.5664e-02, -1.8861e-01,  3.0206e-01,\n",
      "        -6.3802e-01,  9.0942e-03, -4.3311e-01,  7.2815e-02, -8.0511e-02,\n",
      "         6.7749e-02, -6.3599e-02, -5.0456e-01, -2.1393e-01,  2.7856e-01,\n",
      "         1.9017e-01, -2.3529e-02, -2.1362e-03, -2.9486e-01, -2.0279e-02,\n",
      "        -2.7733e-01,  5.6409e-01, -1.9348e-01,  4.7528e-01,  2.8595e-02,\n",
      "         2.5146e-01,  1.6583e-01, -3.8257e-01, -2.2729e-01, -2.2437e-01,\n",
      "        -2.0129e-01, -2.7604e-01, -1.8314e-01,  7.7124e-01, -4.0448e-01,\n",
      "        -2.5671e-01, -3.8330e-02,  3.3862e-01,  2.4385e-01,  1.2096e-01,\n",
      "         4.0338e-01, -6.5971e-02,  7.9836e-01,  3.8342e-01,  2.2669e-01,\n",
      "        -3.8748e-01, -1.8903e-01,  2.4120e-01, -3.9466e-01,  2.9356e-01,\n",
      "         3.2886e-01,  3.4929e+00, -6.0776e-02,  9.6857e-01, -3.1201e-01,\n",
      "        -1.8881e+00, -2.8625e-02, -3.2589e-01, -1.0733e+00, -4.9420e-01,\n",
      "         7.5186e-01, -1.1285e-01,  2.7104e-01,  4.2313e-01, -4.1257e-01,\n",
      "        -6.8283e-01, -3.5889e-02,  8.8351e-01, -1.1765e-01,  4.7260e-01,\n",
      "         6.3568e-01, -2.7069e-02, -4.4390e-01,  2.0941e-01, -2.9505e-01,\n",
      "        -2.0058e-01,  4.7462e-01, -6.0558e-01, -1.5799e+00, -4.0707e-01,\n",
      "         3.4325e-02, -3.2857e-01,  3.4905e-01,  7.5580e-01,  7.4730e-01,\n",
      "         5.0923e-01, -2.3022e-01,  2.8759e-01, -5.9238e-01,  6.6284e-02,\n",
      "         1.6083e-01, -5.8116e-01, -1.6231e-01, -5.3090e-01, -4.3079e-01,\n",
      "         5.7922e-02,  7.6923e-01,  2.9211e-01, -3.6963e-01,  4.7504e-01,\n",
      "        -6.7160e-01, -2.2261e+00,  5.3818e-01, -6.5417e-01, -2.0819e-01,\n",
      "        -1.6605e-01,  3.5492e-01,  1.0974e-01, -1.7119e-01, -5.7812e-01,\n",
      "        -1.5472e-01,  7.3349e-02,  3.6551e-01,  5.1483e-02, -2.9779e-01,\n",
      "         6.4148e-02,  2.7458e-01, -4.9719e-01,  6.4169e-01, -2.8770e-02,\n",
      "        -7.9956e-01,  2.2318e-01, -5.7814e-01,  7.7135e-01, -2.5745e-01,\n",
      "        -2.4768e-01, -1.6235e-02,  1.3721e-01, -1.2203e+00,  1.4600e-01,\n",
      "         1.5942e-01, -1.1823e-01,  2.3804e-02, -5.6482e-01, -6.7499e-01,\n",
      "         1.3516e-01, -4.7977e-01,  2.6260e-01, -3.5938e-01, -2.5635e-03,\n",
      "        -4.3652e-01,  3.1323e-01, -9.2505e-01, -2.5092e-01, -2.9358e-01,\n",
      "         1.6501e-01, -2.3550e-01,  2.3267e-01, -1.3337e-01,  5.5023e-01,\n",
      "        -5.4855e-02,  2.5369e-01, -9.8498e-01,  2.4066e-01, -2.1075e-01,\n",
      "         4.3091e-02,  1.3448e-01, -1.9727e-01,  4.2993e-01,  1.6357e-01,\n",
      "        -6.7151e-01,  5.4312e-01,  1.0796e-01, -4.2923e-02, -6.3257e-01,\n",
      "         1.0189e+00, -7.6355e-02,  2.6146e+00, -3.2749e-02, -3.4814e-01,\n",
      "         3.0261e-01,  8.9447e-02, -5.8911e-01, -2.8587e-01,  4.8059e-01,\n",
      "         1.7285e-01,  5.1453e-02,  2.4101e-01,  9.0546e-02, -5.1880e-04,\n",
      "         2.4304e-01,  5.5164e-01, -7.4027e-01, -7.3509e-01,  1.3641e-02,\n",
      "         6.1279e-02, -7.1526e-03,  1.6314e-01, -1.8271e-01, -3.4702e-01,\n",
      "        -5.1184e-01, -6.6192e-01, -1.4417e-01, -3.8217e-01,  7.3846e-01,\n",
      "        -3.5737e-01,  4.1521e-01, -1.3359e-02, -3.7317e-01, -4.2844e-01,\n",
      "        -4.2000e-01,  2.6630e-01, -5.2032e-02,  1.8779e+00, -6.7764e-02,\n",
      "        -6.9545e-01,  4.8828e-01,  1.6162e-01, -3.7860e-01,  3.8171e-01,\n",
      "        -3.4927e-01,  4.5800e-01,  4.6469e-01, -4.5459e-01, -3.7720e-01,\n",
      "        -1.3334e-01,  2.1767e-01,  1.9542e-01,  5.4779e-03, -2.4581e-01,\n",
      "        -6.6785e-01, -4.3037e-02, -5.3918e-01,  6.1852e-01,  1.5411e-01,\n",
      "         3.1190e-01,  1.0744e-01, -9.9014e-02,  8.6374e-01, -4.1872e-02,\n",
      "         5.1667e-01, -1.0440e-01,  3.8463e-01, -1.9473e-01,  2.5108e-01,\n",
      "        -5.9593e-02,  1.8890e-01,  7.2763e-01,  1.6380e+00, -2.8275e-01,\n",
      "        -9.1621e-02,  2.0142e-01,  1.8817e-01, -3.8675e-01,  1.4947e-01,\n",
      "        -5.5193e-01,  2.7429e-01, -2.7203e-01, -2.3532e-01,  3.3990e-01,\n",
      "        -1.7493e-01, -4.9512e-01, -3.0600e-01,  5.3857e-01,  7.2879e-01,\n",
      "        -1.6930e-01, -2.8552e-01, -2.5522e-01, -9.9426e-02, -6.1127e-01,\n",
      "         7.0313e-01, -5.3931e-01,  2.4017e-02, -6.3193e-01, -1.2030e-01,\n",
      "        -1.5668e-01,  3.4717e-01,  3.2861e-01, -3.7201e-01,  7.7856e-01,\n",
      "        -5.9563e-02, -4.6271e-01, -3.8550e-01, -1.1187e+00, -4.9274e-01,\n",
      "         1.4276e-01, -3.5663e-01,  3.1699e-01, -2.4521e-01,  4.1776e-01,\n",
      "         3.0847e-01,  2.9633e-02,  2.4680e-01, -9.8145e-02,  1.0238e+00,\n",
      "        -2.0129e-01, -4.4741e-01,  5.1208e-01, -1.0916e+00,  2.3746e-01,\n",
      "         3.5986e-01, -1.5395e-01, -2.8348e-01,  5.5225e-01,  3.3545e-01,\n",
      "         1.9420e-01,  5.4416e-01, -6.6931e-01, -2.8052e+00,  8.0005e-01,\n",
      "         8.1177e-03,  7.5745e-01,  4.1010e-01, -5.3699e-01,  3.8895e-01,\n",
      "         2.8561e-01, -1.7245e-01, -5.7678e-01,  7.5873e-01,  1.4862e-01,\n",
      "        -3.1542e-01, -9.5577e-02, -5.2757e-02, -7.1869e-02,  5.6244e-02,\n",
      "        -2.8314e-01,  4.6809e-01, -4.8660e-02, -1.5292e+00, -3.8391e-01,\n",
      "         5.2594e-01, -4.5035e-01, -6.4391e-01,  1.6340e+00,  6.0416e-01,\n",
      "        -2.3431e-01, -7.3074e-02, -9.8450e-02, -2.0974e-01, -1.0996e-01,\n",
      "        -1.0809e+00, -2.3918e-01,  2.8224e-01,  3.2124e-01,  5.1051e-01,\n",
      "         2.8500e-02,  3.2928e-01, -1.1821e-01,  2.4417e-01,  5.0534e-01,\n",
      "         3.2452e-01, -7.0694e-01,  4.5901e-01, -8.7418e-02, -2.1820e-02,\n",
      "         6.6589e-02,  2.3043e-02,  2.0550e+00,  1.1678e-01,  7.4187e-01,\n",
      "        -7.8706e-01,  3.2487e-01,  5.5169e-01, -7.0221e-02, -3.6552e-02,\n",
      "         2.0496e-01,  1.6504e-01,  2.9150e-01, -2.2522e-01, -5.3033e-01,\n",
      "        -1.3788e-01,  9.6802e-02, -3.9612e-02, -5.1521e-01, -1.3815e-01,\n",
      "        -9.3456e-02, -7.8745e-01,  1.6968e-02,  2.3137e-01, -6.1188e-01,\n",
      "        -1.9049e-01,  9.6893e-02,  3.1367e-01,  4.2511e-02, -8.9851e-02,\n",
      "         2.4814e-01,  3.5767e-01, -1.6501e-01,  7.0547e-01,  7.6396e-01,\n",
      "         2.9560e-01,  3.8254e-01,  1.7145e-01, -3.0119e-01,  5.0491e-02,\n",
      "        -1.1118e-01,  2.5299e-02, -1.3921e-01, -3.1543e-01, -3.0762e-02,\n",
      "        -2.7916e-02,  7.2289e-02, -1.8023e-01, -1.0268e-01,  1.8915e-01,\n",
      "        -5.1685e-01, -4.7980e-01, -8.6037e-02,  1.4575e-01,  2.9779e-01,\n",
      "         9.0887e-01, -2.8299e-01,  1.1142e+00,  1.2082e-01,  3.5497e-01,\n",
      "         3.1739e-01, -1.1378e-01, -2.4493e-01,  4.4655e-02,  5.8755e-01,\n",
      "         3.1973e-01, -2.0746e-01,  1.7741e-01,  4.2509e-01, -1.8172e-01,\n",
      "         1.1059e+00, -2.1492e+00,  1.4259e-01,  2.4577e-01,  1.7609e-02,\n",
      "         1.0863e-01, -1.4221e+00,  1.8454e-01,  3.6090e-01,  6.6748e-01,\n",
      "         2.9144e-02,  1.6987e-02, -4.3219e-01,  3.2104e-01, -2.3010e-01,\n",
      "        -4.3396e-01,  1.5919e+00,  1.6080e-01, -2.8912e-01, -1.1353e-01,\n",
      "         1.3937e-01,  2.6058e-01, -1.3199e-01], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(p1[-13]-p2[-13])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
